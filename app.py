
# Application Streamlit : Pr√©diction d'ouverture de compte bancaire (Inclusion financi√®re)
# Tout le code est comment√© en fran√ßais, ligne par ligne, avec des variables nomm√©es en fran√ßais.
# Les ‚Äúpages‚Äù sont organis√©es en onglets pour un d√©ploiement simple sur Streamlit.

# -----------------------------
# 1) Importations des biblioth√®ques
# -----------------------------
import os  # Chargeons os pour manipuler les chemins de fichiers
import io  # Chargeons io pour g√©rer des flux m√©moire (t√©l√©chargements)
import pickle  # Chargeons pickle pour s√©rialiser/d√©s√©rialiser le mod√®le (utilis√© pour export)
import numpy as np  # Chargeons numpy pour le calcul scientifique
import pandas as pd  # Chargeons pandas pour manipuler les tableaux de donn√©es
import plotly.express as px  # Chargeons plotly.express pour des graphiques interactifs
import plotly.graph_objects as go  # Chargeons plotly.graph_objects pour des graphiques personnalis√©s
import streamlit as st  # Chargeons Streamlit pour construire l'interface web
from imblearn.over_sampling import SMOTE  # Chargeons SMOTE pour √©quilibrer des classes minoritaires
from imblearn.pipeline import Pipeline as ImbPipeline  # Chargeons Pipeline (imblearn) pour cha√Æner √©tapes + SMOTE
from sklearn.compose import ColumnTransformer  # Chargeons ColumnTransformer pour appliquer des traitements par colonne
from sklearn.preprocessing import OneHotEncoder, StandardScaler  # Chargeons OneHotEncoder/StandardScaler pour encoder/scaler
from sklearn.model_selection import train_test_split  # Chargeons train_test_split pour s√©parer train/test
from sklearn.ensemble import RandomForestClassifier  # Chargeons RandomForestClassifier pour mod√©liser la cible
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score  # Chargeons les m√©triques utiles
from sklearn.utils import Bunch  # Chargeons Bunch pour structurer des retours lisibles
import streamlit.components.v1 as composants  # Chargeons components pour int√©grer le rapport HTML de profiling

# >>> AJOUT : persistance compacte du mod√®le
import joblib  # Chargeons joblib pour (d√©)serialiser en .pkl.gz

# -----------------------------
# 2) Configuration de la page Streamlit
# -----------------------------
st.set_page_config(  # D√©finissons la configuration g√©n√©rale de la page Streamlit
    page_title="Inclusion financi√®re | Pr√©diction d'ouverture de compte",  # Titre de l‚Äôonglet navigateur
    page_icon="üí≥",  # Ic√¥ne affich√©e dans l‚Äôonglet
    layout="wide"  # Largeur pleine pour profiter de l‚Äôespace
)

# -----------------------------
# 3) Chemins et constantes du projet
# -----------------------------
CHEMIN_FICHIER_DONNEES = "Financial_inclusion_dataset.csv"  # D√©finissons le chemin du fichier de donn√©es CSV
CHEMIN_PROFILING_HTML = "output.html"  # D√©finissons le chemin du rapport HTML de profiling (ydata-profiling)
# >>> AJOUT : chemin de l‚Äôartefact mod√®le compress√©
CHEMIN_MODELE_PKL = "modele_inclusion.pkl.gz"  # Mod√®le compress√© (gzip) persistant entre les runs

SEED_ALEATOIRE = 42  # Fixons une graine pour la reproductibilit√©
TAILLE_TEST = 0.2  # D√©finissons la taille du jeu de test (20%)
NB_ARBRES_RF = 300  # Fixons le nombre d‚Äôarbres du RandomForest pour un bon compromis vitesse/performance

# -----------------------------
# 4) Dictionnaires de renommage des colonnes (anglais -> fran√ßais)
# -----------------------------
#    Chargeons un mapping clair pour renommer les colonnes en fran√ßais (am√©liore la lisibilit√© c√¥t√© EDA).
RENOMMAGE_COLONNES = {  # D√©finissons un dictionnaire pour renommer les colonnes en fran√ßais
    "country": "pays",
    "year": "annee",
    "uniqueid": "identifiant_unique",
    "bank_account": "compte_bancaire",
    "location_type": "type_localisation",
    "cellphone_access": "acces_telephone",
    "household_size": "taille_menage",
    "age_of_respondent": "age_repondant",
    "gender_of_respondent": "genre_repondant",
    "relationship_with_head": "relation_chef_menage",
    "marital_status": "statut_matrimonial",
    "education_level": "niveau_education",
    "job_type": "type_emploi",
}

# -----------------------------
# 5) Fonctions utilitaires (chargement, renommage, pr√©paration)
# -----------------------------

@st.cache_data(show_spinner=True)  # M√©morisons le r√©sultat pour √©viter de recharger √† chaque interaction
def charger_donnees() -> pd.DataFrame:
    """Chargeons le fichier CSV officiel pour obtenir le jeu de donn√©es brut."""
    # V√©rifions l'existence du fichier et signalons un message clair si absent
    if not os.path.exists(CHEMIN_FICHIER_DONNEES):  # Si le fichier n'existe pas
        st.error(f"Fichier introuvable : {CHEMIN_FICHIER_DONNEES}")  # Affichons une erreur utilisateur
        return pd.DataFrame()  # Retournons un DataFrame vide pour √©viter une exception
    # Lisons le CSV dans un DataFrame pandas
    donnees = pd.read_csv(CHEMIN_FICHIER_DONNEES)  # Chargeons le jeu de donn√©es complet
    return donnees  # Retournons le DataFrame charg√©

def renommer_colonnes_en_francais(donnees: pd.DataFrame) -> pd.DataFrame:
    """Renommons les colonnes techniques en fran√ßais pour une meilleure lisibilit√© c√¥t√© exploration."""
    # Copions les donn√©es pour √©viter les effets de bord
    donnees_copie = donnees.copy()  # Cr√©ons une copie s√ªre du DataFrame d‚Äôentr√©e
    # Appliquons le dictionnaire de renommage
    donnees_copie = donnees_copie.rename(columns=RENOMMAGE_COLONNES)  # Renommons les colonnes
    return donnees_copie  # Retournons la version renomm√©e

def colonnes_par_type(donnees_fr: pd.DataFrame) -> Bunch:
    """Identifions les colonnes num√©riques et cat√©gorielles apr√®s renommage fran√ßais."""
    # S√©lectionnons les colonnes num√©riques par type
    colonnes_numeriques = donnees_fr.select_dtypes(include=[np.number]).columns.tolist()  # R√©cup√©rons les colonnes num√©riques
    # S√©lectionnons les colonnes cat√©gorielles par type
    colonnes_categorielles = donnees_fr.select_dtypes(exclude=[np.number]).columns.tolist()  # R√©cup√©rons les colonnes non num√©riques
    # Retournons un Bunch (objet pratique type dict) avec les deux listes
    return Bunch(numeriques=colonnes_numeriques, categorielles=colonnes_categorielles)

def preparer_cible(donnees_fr: pd.DataFrame) -> pd.Series:
    """Convertissons la cible 'compte_bancaire' (Yes/No) en binaire (1/0) en conservant le reste intact."""
    # Copions pour ne pas alt√©rer l‚Äôoriginal
    donnees_copie = donnees_fr.copy()  # Cr√©ons une copie pour travailler proprement
    # Convertissons la cible en 1/0 sans changer les autres colonnes
    cible_binaire = donnees_copie["compte_bancaire"].map({"Yes": 1, "No": 0})  # Mappage simple Yes->1, No->0
    return cible_binaire  # Retournons la s√©rie cible binaire

def separer_X_y(donnees_fr: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:
    """S√©parons X (caract√©ristiques) et y (cible) √† partir du DataFrame en fran√ßais."""
    # Isolons y (cible)
    y_cible = preparer_cible(donnees_fr)  # Construisons la cible binaire 1/0
    # Retirons de X la cible et un identifiant qui n‚Äôapporte rien au mod√®le
    X_entree = donnees_fr.drop(columns=["compte_bancaire", "identifiant_unique"], errors="ignore")  # Supprimons la cible et l‚Äôidentifiant
    return X_entree, y_cible  # Retournons X et y

def construire_transformeur(X: pd.DataFrame) -> ColumnTransformer:
    """Construisons un ColumnTransformer bas√© sur les colonnes pr√©sentes dans X (et pas le DF complet)."""
    types = colonnes_par_type(X)

    transformers = []
    if types.numeriques:
        transformers.append(("num", StandardScaler(), types.numeriques))
    if types.categorielles:
        # SMOTE exige du dense ; on garde OneHotEncoder en dense
        transformers.append(("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), types.categorielles))

    if not transformers:
        # Rien √† transformer => levons une erreur explicite
        raise ValueError("Aucune colonne exploitable pour l'entra√Ænement (ni num√©rique ni cat√©gorielle).")

    return ColumnTransformer(transformers=transformers, remainder="drop")


@st.cache_resource(show_spinner=True)  # M√©morisons la ressource entra√Æn√©e (mod√®le) entre interactions
def entrainer_modele(donnees_fr: pd.DataFrame) -> Bunch:
    """Entra√Ænons un mod√®le RandomForest dans un pipeline : pr√©traitement -> SMOTE -> RandomForest."""
    # S√©parons X et y
    X_entree, y_cible = separer_X_y(donnees_fr)  # Pr√©parons les entr√©es et la cible
    # Construisons le transformeur de colonnes
    transformeur = construire_transformeur(X_entree)  # Cr√©ons le transformeur colonnes
    # Instancions le classifieur RandomForest
    classifieur = RandomForestClassifier(  # D√©finissons le mod√®le final
        n_estimators=NB_ARBRES_RF,  # Fixons le nombre d‚Äôarbres
        random_state=SEED_ALEATOIRE,  # Assurons la reproductibilit√©
        n_jobs=-1,  # Utilisons tous les c≈ìurs disponibles
        class_weight=None  # La gestion du d√©s√©quilibre est confi√©e √† SMOTE, pas aux poids
    )
    # Construisons un pipeline imbalanced-learn avec SMOTE entre le pr√©traitement et le classifieur
    pipeline = ImbPipeline(  # Cha√Ænons les √©tapes dans l‚Äôordre logique
        steps=[
            ("pretraitement", transformeur),  # Appliquons le transformeur (scaler + one-hot)
            ("smote", SMOTE(random_state=SEED_ALEATOIRE)),  # √âquilibrons les classes dans l‚Äôespace transform√©
            ("modele", classifieur),  # Appliquons le classifieur RF sur les donn√©es √©quilibr√©es
        ]
    )
    # D√©coupons en apprentissage/test
    X_app, X_test, y_app, y_test = train_test_split(  # S√©parons apprentissage et test
        X_entree, y_cible, test_size=TAILLE_TEST, random_state=SEED_ALEATOIRE, stratify=y_cible  # Stratifier pour garder le ratio
    )
    # Entra√Ænons le pipeline
    pipeline.fit(X_app, y_app)  # Ajustons l‚Äôensemble des √©tapes sur les donn√©es d‚Äôapprentissage
    # Pr√©dictions de contr√¥le sur le test
    y_pred = pipeline.predict(X_test)  # Pr√©dictions classes
    y_proba = pipeline.predict_proba(X_test)[:, 1]  # Probabilit√©s classe positive
    # Calculons des m√©triques cl√©s
    exactitude = accuracy_score(y_test, y_pred)  # Calculons l‚Äôaccuracy globale
    matrice = confusion_matrix(y_test, y_pred)  # Construisons la matrice de confusion
    rapport = classification_report(y_test, y_pred, output_dict=True)  # G√©n√©rons un rapport d√©taill√© (dict)
    # Retournons toutes les infos utiles dans un Bunch
    return Bunch(
        pipeline=pipeline,  # Renvoyons le pipeline complet pr√™t pour la pr√©diction
        X_test=X_test,  # Conserver X_test pour visualisations
        y_test=y_test,  # Conserver y_test pour m√©triques
        y_pred=y_pred,  # Conserver y_pred pour m√©triques
        y_proba=y_proba,  # Conserver y_proba pour courbes/threshold
        exactitude=exactitude,  # Score accuracy
        matrice=matrice,  # Matrice de confusion
        rapport=rapport  # Rapport d√©taill√© (precision/recall/f1)
    )

# >>> AJOUT : helpers de persistance mod√®le
def sauver_modele_compresse(pipeline, chemin: str = CHEMIN_MODELE_PKL):
    """Sauvegardons le pipeline en .pkl.gz (joblib + gzip) pour persister entre les lancements."""
    joblib.dump(pipeline, chemin, compress=("gzip", 3))  # Compression niveau 3 = bon ratio/temps

def charger_modele_si_dispo(chemin: str = CHEMIN_MODELE_PKL):
    """Rechargeons le pipeline s‚Äôil existe d√©j√† sur disque, sinon None."""
    if os.path.exists(chemin):
        try:
            return joblib.load(chemin)
        except Exception as e:
            st.warning(f"Impossible de charger le mod√®le existant ({e}). Il sera r√©entra√Æn√©.")
    return None

def dataframe_vers_csv_bytes(df: pd.DataFrame) -> bytes:
    """Convertissons un DataFrame en CSV (bytes) pour permettre le t√©l√©chargement sans √©crire sur disque."""
    # Cr√©ons un tampon m√©moire texte
    tampon = io.StringIO()  # Ouvrons un buffer en m√©moire
    # √âcrivons le DataFrame en CSV dans le tampon
    df.to_csv(tampon, index=False)  # Exportons sans l‚Äôindex
    # Convertissons en bytes
    return tampon.getvalue().encode("utf-8")  # Retournons les octets encod√©s en UTF-8

def dictionnaire_variables(donnees_fr: pd.DataFrame) -> pd.DataFrame:
    """Construisons un mini dictionnaire de donn√©es (nom, type, % manquants, exemples)."""
    # Pr√©parons une liste pour collecter les m√©ta-informations
    lignes = []  # Initialisons un conteneur vide
    # Parcourons chaque colonne pour en extraire les infos utiles
    for nom_colonne in donnees_fr.columns:  # It√©rons sur les colonnes
        type_col = str(donnees_fr[nom_colonne].dtype)  # R√©cup√©rons le type pandas de la colonne
        manquants = int(donnees_fr[nom_colonne].isna().sum())  # Comptons le nombre de valeurs manquantes
        pct_manq = round(100 * manquants / len(donnees_fr), 2)  # Calculons le pourcentage de manquants
        exemple = donnees_fr[nom_colonne].dropna().unique()[:3]  # Prenons quelques exemples de valeurs
        lignes.append({  # Ajoutons une ligne d'information
            "variable": nom_colonne,
            "type": type_col,
            "valeurs_exemple": list(exemple),
            "manquants": manquants,
            "%_manquants": pct_manq
        })
    # Convertissons la liste en DataFrame structur√©
    return pd.DataFrame(lignes)  # Retournons la table du dictionnaire

# -----------------------------
# 6) Chargement des donn√©es brutes, renommage et pr√©paration
# -----------------------------
donnees_brutes = charger_donnees()  # Chargeons le fichier CSV pour obtenir le dataset d‚Äôorigine
donnees_fr = renommer_colonnes_en_francais(donnees_brutes)  # Renommons les colonnes en fran√ßais pour l‚ÄôEDA

# Assurons-nous d'avoir une cl√© de session pour le mod√®le
if "modele_infos" not in st.session_state:
    st.session_state["modele_infos"] = None

# >>> AJOUT : Amor√ßage automatique du mod√®le (premier lancement)
if not donnees_fr.empty:
    with st.spinner("Initialisation du mod√®le‚Ä¶"):
        pipeline_disque = charger_modele_si_dispo()  # Tentons de charger un artefact existant
        if pipeline_disque is None:
            # Aucun artefact : entra√Ænons maintenant et sauvegardons
            infos_init = entrainer_modele(donnees_fr)  # Entra√Ænons le mod√®le initial
            sauver_modele_compresse(infos_init.pipeline)  # Persistance .pkl.gz pour les prochains runs
            st.session_state["modele_infos"] = infos_init  # Gardons aussi les m√©triques en session
            st.success(f"Mod√®le initial entra√Æn√© et sauvegard√© (accuracy = {infos_init.exactitude:.3f}).")
        else:
            # Artefact d√©j√† pr√©sent : utilisons-le imm√©diatement
            st.session_state["modele_infos"] = Bunch(pipeline=pipeline_disque)  # Pas de m√©triques tant qu‚Äôon ne r√©entra√Æne pas
            st.info("Mod√®le charg√© depuis le disque (artefact compress√©). "
                    "Cliquez sur **R√©entra√Æner** pour g√©n√©rer de nouvelles m√©triques sur ce run.")

# -----------------------------
# 7) Barre d‚Äôent√™te (titre + rappel)
# -----------------------------
st.title("üí≥ Inclusion financi√®re ‚Äì Pr√©diction d'ouverture de compte bancaire")  # Affichons un titre clair
st.caption("Exploration, pr√©traitement, mod√©lisation et pr√©diction ‚Äì dataset d‚Äôinclusion financi√®re.")  # Ajoutons un sous-titre

# -----------------------------
# 8) Organisation en onglets (pages logiques)
# -----------------------------
onglets = st.tabs([  # Cr√©ons des onglets pour structurer l‚Äôapplication
    "üè† Accueil",            # Onglet 0 : Accueil
    "üîç Exploration",        # Onglet 1 : Exploration des donn√©es
    "üßπ Pr√©traitement",      # Onglet 2 : Pr√©traitement (manquants, doublons, √©quilibrage)
    "ü§ñ Mod√©lisation",       # Onglet 3 : Entra√Ænement et √©valuation du mod√®le
    "üéØ Pr√©diction",         # Onglet 4 : Interface de pr√©diction
    "üìë Profiling",          # Onglet 5 : Rapport ydata-profiling (HTML)
    "‚¨áÔ∏è T√©l√©chargements",    # Onglet 6 : Export des artefacts
    "‚ÑπÔ∏è √Ä propos"            # Onglet 7 : Contexte et objectifs
])

# -----------------------------
# 9) Onglet : Accueil
# -----------------------------
with onglets[0]:  # Entrons dans l‚Äôonglet Accueil
    st.subheader("Bienvenue üëã")  # Affichons un sous-titre convivial
    # Pr√©sentons le projet en quelques points cl√©s
    st.markdown(  # R√©digeons une description du projet pour situer l‚Äôutilisateur
        """
        **Objet du projet :** analyser et pr√©dire la probabilit√© qu‚Äôun individu poss√®de un compte bancaire,
        afin d‚Äô√©clairer des actions favorisant l‚Äôinclusion financi√®re.

        **Ce que vous pouvez faire ici :**
        - Explorer le jeu de donn√©es (profils, distributions, corr√©lations)
        - Visualiser le pr√©traitement (manquants, doublons, valeurs atypiques)
        - Entra√Æner un mod√®le *Random Forest* (avec SMOTE pour traiter le d√©s√©quilibre)
        - Tester des pr√©dictions sur des profils personnalis√©s
        - Consulter et t√©l√©charger le rapport de *profiling* et les artefacts (mod√®le, donn√©es pr√©par√©es)
        """
    )
    # Affichons quelques KPI rapides
    col_a, col_b, col_c, col_d = st.columns(4)  # Cr√©ons une grille de 4 colonnes pour les indicateurs
    with col_a:  # Dans la 1√®re colonne
        st.metric("Observations", value=f"{len(donnees_fr):,}".replace(",", " "))  # Affichons le nombre d‚Äôobservations
    with col_b:  # Dans la 2√®me colonne
        nb_vars = len(donnees_fr.columns)  # Comptons le nombre de variables
        st.metric("Variables", value=nb_vars)  # Affichons le nombre de colonnes
    with col_c:  # Dans la 3√®me colonne
        part_yes = (donnees_fr["compte_bancaire"].eq("Yes").mean() * 100) if not donnees_fr.empty else 0  # Calculons le % Yes
        st.metric("% Comptes (Yes)", value=f"{part_yes:.1f}%")  # Affichons le pourcentage de comptes
    with col_d:  # Dans la 4√®me colonne
        st.metric("Pays distincts", value=donnees_fr["pays"].nunique() if not donnees_fr.empty else 0)  # Affichons le nb de pays

# -----------------------------
# 10) Onglet : Exploration
# -----------------------------
with onglets[1]:  # Entrons dans l‚Äôonglet Exploration
    st.subheader("Aper√ßu des donn√©es")  # Affichons un sous-titre
    # Montrons les 10 premi√®res lignes pour un aper√ßu rapide
    st.dataframe(donnees_fr.head(10), use_container_width=True)  # Pr√©sentons un √©chantillon des donn√©es
    # Ajoutons des stats descriptives num√©riques
    st.subheader("Statistiques descriptives (num√©riques)")  # Indiquons la section de stats
    st.dataframe(donnees_fr.describe(include=[np.number]), use_container_width=True)  # R√©sumons les colonnes num√©riques
    # Ajoutons une table sur les manquants
    st.subheader("Valeurs manquantes")  # Indiquons la section sur les valeurs manquantes
    tableau_manquants = pd.DataFrame({  # Construisons un tableau synth√©tique des manquants
        "variable": donnees_fr.columns,
        "nb_manquants": donnees_fr.isna().sum().values,
        "%_manquants": (100 * donnees_fr.isna().sum().values / len(donnees_fr)).round(2)
    })  # Fermons la construction du DataFrame
    st.dataframe(tableau_manquants, use_container_width=True)  # Affichons la table des manquants
    # Visualisation : distribution √¢ge par pays (boxplot)
    st.subheader("Distribution de l‚Äô√¢ge par pays")  # Annon√ßons la visualisation
    if not donnees_fr.empty:  # V√©rifions que des donn√©es existent
        fig_age = px.box(donnees_fr, x="pays", y="age_repondant", points="outliers", title="√Çge par pays")  # Cr√©ons un boxplot
        st.plotly_chart(fig_age, use_container_width=True)  # Affichons le graphique
    # Dictionnaire de donn√©es synth√©tique
    st.subheader("Dictionnaire de donn√©es (vue rapide)")  # Indiquons la section
    st.dataframe(dictionnaire_variables(donnees_fr), use_container_width=True)  # Affichons le dictionnaire rapide

# -----------------------------
# 11) Onglet : Pr√©traitement
# -----------------------------
with onglets[2]:  # Entrons dans l‚Äôonglet Pr√©traitement
    st.subheader("Contr√¥les de qualit√©")  # Affichons un sous-titre
    # Comptage de doublons
    nb_doublons = int(donnees_fr.duplicated().sum())  # Comptons les doublons ligne √† ligne
    st.write(f"**Doublons d√©tect√©s :** {nb_doublons}")  # Affichons le nombre de doublons
    # Affichons les colonnes num√©riques pour une d√©tection visuelle d‚Äôoutliers
    st.subheader("Valeurs atypiques ‚Äì aper√ßu (bo√Ætes √† moustaches)")  # Indiquons la section outliers
    colonnes_num = donnees_fr.select_dtypes(include=[np.number]).columns.tolist()  # R√©cup√©rons les colonnes num√©riques
    for nom_col in colonnes_num:  # Parcourons chaque colonne num√©rique
        fig_box = go.Figure()  # Initialisons une figure Plotly
        fig_box.add_trace(go.Box(y=donnees_fr[nom_col], name=nom_col))  # Ajoutons une bo√Æte √† moustaches
        fig_box.update_layout(title=f"Bo√Æte √† moustaches ‚Äì {nom_col}")  # Donnons un titre lisible
        st.plotly_chart(fig_box, use_container_width=True)  # Affichons le graphique

# -----------------------------
# 12) Onglet : Mod√©lisation
# -----------------------------
with onglets[3]:  # Entrons dans l‚Äôonglet Mod√©lisation
    st.subheader("Entra√Ænement du mod√®le")  # Affichons un sous-titre

    # Bouton d‚Äôentra√Ænement pour d√©clencher le calcul et (r√©)√©crire l‚Äôartefact
    if st.button("üîÅ Entra√Æner / R√©entra√Æner le mod√®le"):
        infos = entrainer_modele(donnees_fr)  # Entra√Ænons et r√©cup√©rons les objets utiles
        st.session_state["modele_infos"] = infos  # Conservons toutes les m√©triques en session
        sauver_modele_compresse(infos.pipeline)  # Sauvegardons l‚Äôartefact compress√©
        st.success(f"Mod√®le (r√©)entra√Æn√© et sauvegard√©. Exactitude (accuracy) : {infos.exactitude:.3f}")

    # Affichage des m√©triques si disponibles
    infos = st.session_state.get("modele_infos", None)
    if infos is not None and hasattr(infos, "matrice"):
        # Affichons la matrice de confusion
        st.subheader("Matrice de confusion (jeu de test)")
        matrice = infos.matrice
        fig_cf = go.Figure(data=go.Heatmap(
            z=matrice,
            x=["Pr√©dit: Non", "Pr√©dit: Oui"],
            y=["R√©el: Non", "R√©el: Oui"],
            text=matrice,
            texttemplate="%{text}",
            colorscale="Blues"
        ))
        fig_cf.update_layout(title="Matrice de confusion")
        st.plotly_chart(fig_cf, use_container_width=True)

        # Affichons un r√©sum√© de classification (pr√©cision/rappel/F1)
        st.subheader("Rapport de classification")
        rapport_df = pd.DataFrame(infos.rapport).transpose()
        st.dataframe(rapport_df, use_container_width=True)
    elif infos is not None:
        st.info("Mod√®le charg√© depuis le disque. R√©entra√Ænez pour afficher les m√©triques de ce run.")

# -----------------------------
# 13) Onglet : Pr√©diction
# -----------------------------
with onglets[4]:  # Entrons dans l‚Äôonglet Pr√©diction
    st.subheader("Pr√©dire l‚Äôouverture d‚Äôun compte bancaire")  # Affichons un sous-titre
    # R√©cup√©rons un mod√®le depuis la session si disponible
    infos = st.session_state.get("modele_infos", None)  # Lisons le mod√®le en session
    if infos is None:
        st.info("Le mod√®le n'est pas encore disponible. V√©rifiez l'onglet **Mod√©lisation**.")
    elif not hasattr(infos, "pipeline"):
        st.info("Le mod√®le charg√© est incomplet. R√©entra√Ænez-le dans l‚Äôonglet **Mod√©lisation**.")
    else:
        # Construisons un formulaire utilisateur
        with st.form("formulaire_prediction"):  # Cr√©ons un formulaire pour regrouper les champs
            col_g, col_d = st.columns(2)  # Cr√©ons deux colonnes pour une saisie lisible
            with col_g:  # Colonne gauche : attributs d√©mographiques
                pays = st.selectbox("Pays", sorted(donnees_fr["pays"].dropna().unique()))
                age = st.slider("√Çge du r√©pondant", min_value=15, max_value=100, value=30, step=1)
                genre = st.selectbox("Genre", sorted(donnees_fr["genre_repondant"].dropna().unique()))
                statut = st.selectbox("Statut matrimonial", sorted(donnees_fr["statut_matrimonial"].dropna().unique()))
            with col_d:  # Colonne droite : autres attributs
                local = st.selectbox("Type de localisation", sorted(donnees_fr["type_localisation"].dropna().unique()))
                tel = st.selectbox("Acc√®s au t√©l√©phone", sorted(donnees_fr["acces_telephone"].dropna().unique()))
                taille = st.slider("Taille du m√©nage", min_value=1, max_value=25, value=4, step=1)
                etude = st.selectbox("Niveau d‚Äô√©ducation", sorted(donnees_fr["niveau_education"].dropna().unique()))
                emploi = st.selectbox("Type d‚Äôemploi", sorted(donnees_fr["type_emploi"].dropna().unique()))
                relation = st.selectbox("Relation avec le chef de m√©nage", sorted(donnees_fr["relation_chef_menage"].dropna().unique()))
                annee = st.selectbox("Ann√©e d‚Äôenqu√™te", sorted(donnees_fr["annee"].dropna().unique()))
            # Ajoutons un seuil de probabilit√© ajustable
            seuil = st.slider("Seuil de d√©cision (probabilit√© pour classer 'Oui')", 0.05, 0.95, 0.50, 0.01)
            # Bouton de soumission du formulaire
            soumis = st.form_submit_button("Lancer la pr√©diction")
        # Si l‚Äôutilisateur a soumis le formulaire
        if soumis:
            # Construisons un DataFrame √† une ligne avec les m√™mes noms de colonnes (fran√ßais) que X_entree
            entree_utilisateur = pd.DataFrame([{
                "pays": pays,
                "annee": annee,
                "type_localisation": local,
                "acces_telephone": tel,
                "taille_menage": taille,
                "age_repondant": age,
                "genre_repondant": genre,
                "relation_chef_menage": relation,
                "statut_matrimonial": statut,
                "niveau_education": etude,
                "type_emploi": emploi
            }])
            # Pr√©diction
            proba = infos.pipeline.predict_proba(entree_utilisateur)[:, 1][0]
            classe = int(proba >= seuil)
            # Rendu des r√©sultats
            c1, c2 = st.columns(2)
            with c1:
                st.success(f"Probabilit√© d'avoir un compte : **{proba:.2%}**")
            with c2:
                libelle = "Compte probable (Oui)" if classe == 1 else "Compte peu probable (Non)"
                st.info(f"D√©cision (seuil {seuil:.0%}) : **{libelle}**")

# -----------------------------
# 14) Onglet : Profiling (rapport HTML)
# -----------------------------
with onglets[5]:  # Entrons dans l‚Äôonglet Profiling
    st.subheader("Rapport de profiling (ydata-profiling)")  # Affichons un sous-titre
    if not os.path.exists(CHEMIN_PROFILING_HTML):
        st.warning("Aucun rapport 'output.html' trouv√©. G√©n√©rez-le et placez-le √† la racine.")
    else:
        with open(CHEMIN_PROFILING_HTML, "r", encoding="utf-8") as f:
            contenu_html = f.read()
        composants.html(contenu_html, height=800, scrolling=True)

# -----------------------------
# 15) Onglet : T√©l√©chargements
# -----------------------------
with onglets[6]:  # Entrons dans l‚Äôonglet T√©l√©chargements
    st.subheader("Export des artefacts")
    # Donn√©es renomm√©es
    st.write("T√©l√©chargez les **donn√©es renomm√©es (fran√ßais)** pour vos usages (EDA/archivage) :")
    st.download_button(
        label="‚¨áÔ∏è T√©l√©charger le CSV (colonnes en fran√ßais)",
        data=dataframe_vers_csv_bytes(donnees_fr),
        file_name="donnees_inclusion_fr.csv",
        mime="text/csv"
    )
    # Mod√®le compress√© si disponible
    if os.path.exists(CHEMIN_MODELE_PKL):
        with open(CHEMIN_MODELE_PKL, "rb") as fbin:
            contenu_modele = fbin.read()
        st.download_button(
            label="‚¨áÔ∏è T√©l√©charger le mod√®le (modele_inclusion.pkl.gz)",
            data=contenu_modele,
            file_name="modele_inclusion.pkl.gz",
            mime="application/octet-stream"
        )
    else:
        st.info("Aucun artefact mod√®le √† t√©l√©charger pour l‚Äôinstant (il sera g√©n√©r√© au premier entra√Ænement).")

# -----------------------------
# 16) Onglet : √Ä propos
# -----------------------------
with onglets[7]:  # Entrons dans l‚Äôonglet √Ä propos
    st.subheader("Contexte du projet")
    st.markdown(
        """
        **De quoi s‚Äôagit-il ?**  
        Projet d‚Äôinclusion financi√®re visant √† comprendre et **pr√©dire** l‚Äôouverture d‚Äôun compte bancaire.

        **Probl√®me √† r√©soudre :**  
        Faible taux de bancarisation et difficult√© √† **identifier les profils** susceptibles d‚Äôouvrir un compte.

        **Objectifs :**  
        - Explorer les facteurs socio-d√©mographiques impactant la possession d‚Äôun compte  
        - Construire un **mod√®le pr√©dictif** fiable (RandomForest + SMOTE)  
        - Fournir une **interface** de pr√©diction et d‚Äôanalyse d√©cisionnelle
        """
    )
    st.caption("App Streamlit ‚Äì variables Python en fran√ßais, commentaires d√©taill√©s, profilage int√©gr√©.")
