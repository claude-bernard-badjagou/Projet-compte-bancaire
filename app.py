
# Application Streamlit : Pr√©diction d'ouverture de compte bancaire (Inclusion financi√®re)
# Tout le code est comment√© en fran√ßais, ligne par ligne, avec des variables nomm√©es en fran√ßais.
# Les ‚Äúpages‚Äù sont organis√©es en onglets pour un d√©ploiement simple sur Streamlit.


# -----------------------------
# 1) Importations des biblioth√®ques
# -----------------------------
import os  # Chargeons os pour manipuler les chemins de fichiers
import io  # Chargeons io pour g√©rer des flux m√©moire (t√©l√©chargements)
import pickle  # Chargeons pickle pour s√©rialiser/d√©s√©rialiser le mod√®le
import numpy as np  # Chargeons numpy pour le calcul scientifique
import pandas as pd  # Chargeons pandas pour manipuler les tableaux de donn√©es
import plotly.express as px  # Chargeons plotly.express pour des graphiques interactifs
import plotly.graph_objects as go  # Chargeons plotly.graph_objects pour des graphiques personnalis√©s
import streamlit as st  # Chargeons Streamlit pour construire l'interface web
from imblearn.over_sampling import SMOTE  # Chargeons SMOTE pour √©quilibrer des classes minoritaires
from imblearn.pipeline import Pipeline as ImbPipeline  # Chargeons Pipeline (imblearn) pour cha√Æner √©tapes + SMOTE
from sklearn.compose import ColumnTransformer  # Chargeons ColumnTransformer pour appliquer des traitements par colonne
from sklearn.preprocessing import OneHotEncoder, StandardScaler  # Chargeons OneHotEncoder/StandardScaler pour encoder/scaler
from sklearn.model_selection import train_test_split  # Chargeons train_test_split pour s√©parer train/test
from sklearn.ensemble import RandomForestClassifier  # Chargeons RandomForestClassifier pour mod√©liser la cible
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score  # Chargeons les m√©triques utiles
from sklearn.utils import Bunch  # Chargeons Bunch pour structurer des retours lisibles
import streamlit.components.v1 as composants  # Chargeons components pour int√©grer le rapport HTML de profiling

# -----------------------------
# 2) Configuration de la page Streamlit
# -----------------------------
st.set_page_config(  # D√©finissons la configuration g√©n√©rale de la page Streamlit
    page_title="Inclusion financi√®re | Pr√©diction d'ouverture de compte",  # Titre de l‚Äôonglet navigateur
    page_icon="üí≥",  # Ic√¥ne affich√©e dans l‚Äôonglet
    layout="wide"  # Largeur pleine pour profiter de l‚Äôespace
)

# -----------------------------
# 3) Chemins et constantes du projet
# -----------------------------
CHEMIN_FICHIER_DONNEES = "Financial_inclusion_dataset.csv"  # D√©finissons le chemin du fichier de donn√©es CSV
CHEMIN_PROFILING_HTML = "output.html"  # D√©finissons le chemin du rapport HTML de profiling (ydata-profiling)
SEED_ALEATOIRE = 42  # Fixons une graine pour la reproductibilit√©
TAILLE_TEST = 0.2  # D√©finissons la taille du jeu de test (20%)
NB_ARBRES_RF = 300  # Fixons le nombre d‚Äôarbres du RandomForest pour un bon compromis vitesse/performance

# -----------------------------
# 4) Dictionnaires de renommage des colonnes (anglais -> fran√ßais)
# -----------------------------
#    Chargeons un mapping clair pour renommer les colonnes en fran√ßais (am√©liore la lisibilit√© c√¥t√© EDA).
RENOMMAGE_COLONNES = {  # D√©finissons un dictionnaire pour renommer les colonnes en fran√ßais
    "country": "pays",
    "year": "annee",
    "uniqueid": "identifiant_unique",
    "bank_account": "compte_bancaire",
    "location_type": "type_localisation",
    "cellphone_access": "acces_telephone",
    "household_size": "taille_menage",
    "age_of_respondent": "age_repondant",
    "gender_of_respondent": "genre_repondant",
    "relationship_with_head": "relation_chef_menage",
    "marital_status": "statut_matrimonial",
    "education_level": "niveau_education",
    "job_type": "type_emploi",
}

# -----------------------------
# 5) Fonctions utilitaires (chargement, renommage, pr√©paration)
# -----------------------------

@st.cache_data(show_spinner=True)  # M√©morisons le r√©sultat pour √©viter de recharger √† chaque interaction
def charger_donnees() -> pd.DataFrame:
    """Chargeons le fichier CSV officiel pour obtenir le jeu de donn√©es brut."""
    # V√©rifions l'existence du fichier et signalons un message clair si absent
    if not os.path.exists(CHEMIN_FICHIER_DONNEES):  # Si le fichier n'existe pas
        st.error(f"Fichier introuvable : {CHEMIN_FICHIER_DONNEES}")  # Affichons une erreur utilisateur
        return pd.DataFrame()  # Retournons un DataFrame vide pour √©viter une exception
    # Lisons le CSV dans un DataFrame pandas
    donnees = pd.read_csv(CHEMIN_FICHIER_DONNEES)  # Chargeons le jeu de donn√©es complet
    return donnees  # Retournons le DataFrame charg√©

def renommer_colonnes_en_francais(donnees: pd.DataFrame) -> pd.DataFrame:
    """Renommons les colonnes techniques en fran√ßais pour une meilleure lisibilit√© c√¥t√© exploration."""
    # Copions les donn√©es pour √©viter les effets de bord
    donnees_copie = donnees.copy()  # Cr√©ons une copie s√ªre du DataFrame d‚Äôentr√©e
    # Appliquons le dictionnaire de renommage
    donnees_copie = donnees_copie.rename(columns=RENOMMAGE_COLONNES)  # Renommons les colonnes
    return donnees_copie  # Retournons la version renomm√©e

def colonnes_par_type(donnees_fr: pd.DataFrame) -> Bunch:
    """Identifions les colonnes num√©riques et cat√©gorielles apr√®s renommage fran√ßais."""
    # S√©lectionnons les colonnes num√©riques par type
    colonnes_numeriques = donnees_fr.select_dtypes(include=[np.number]).columns.tolist()  # R√©cup√©rons les colonnes num√©riques
    # S√©lectionnons les colonnes cat√©gorielles par type
    colonnes_categorielles = donnees_fr.select_dtypes(exclude=[np.number]).columns.tolist()  # R√©cup√©rons les colonnes non num√©riques
    # Retournons un Bunch (objet pratique type dict) avec les deux listes
    return Bunch(numeriques=colonnes_numeriques, categorielles=colonnes_categorielles)

def preparer_cible(donnees_fr: pd.DataFrame) -> pd.Series:
    """Convertissons la cible 'compte_bancaire' (Yes/No) en binaire (1/0) en conservant le reste intact."""
    # Copions pour ne pas alt√©rer l‚Äôoriginal
    donnees_copie = donnees_fr.copy()  # Cr√©ons une copie pour travailler proprement
    # Convertissons la cible en 1/0 sans changer les autres colonnes
    cible_binaire = donnees_copie["compte_bancaire"].map({"Yes": 1, "No": 0})  # Mappage simple Yes->1, No->0
    return cible_binaire  # Retournons la s√©rie cible binaire

def separer_X_y(donnees_fr: pd.DataFrame) -> tuple[pd.DataFrame, pd.Series]:
    """S√©parons X (caract√©ristiques) et y (cible) √† partir du DataFrame en fran√ßais."""
    # Isolons y (cible)
    y_cible = preparer_cible(donnees_fr)  # Construisons la cible binaire 1/0
    # Retirons de X la cible et un identifiant qui n‚Äôapporte rien au mod√®le
    X_entree = donnees_fr.drop(columns=["compte_bancaire", "identifiant_unique"], errors="ignore")  # Supprimons la cible et l‚Äôidentifiant
    return X_entree, y_cible  # Retournons X et y

def construire_transformeur(donnees_fr: pd.DataFrame) -> ColumnTransformer:
    """Construisons un ColumnTransformer pour scaler les num√©riques et encoder les cat√©gorielles."""
    # R√©cup√©rons les colonnes num√©riques/cat√©gorielles
    types = colonnes_par_type(donnees_fr)  # Obtenons les listes de colonnes par type
    # D√©finissons le pipeline num√©rique (scaling)
    pipeline_numerique = StandardScaler()  # Standardisons les colonnes num√©riques
    # D√©finissons le pipeline cat√©goriel (One-Hot)
    pipeline_categoriel = OneHotEncoder(handle_unknown="ignore", sparse_output=False)  # Encodons les cat√©gories
    # Assemblons le transformeur par colonnes
    transformeur = ColumnTransformer(  # Cr√©ons le transformeur multi-colonnes
        transformers=[
            ("num", pipeline_numerique, types.numeriques),  # Appliquons le scaler aux colonnes num√©riques
            ("cat", pipeline_categoriel, types.categorielles),  # Appliquons l‚Äôencoder aux colonnes cat√©gorielles
        ],
        remainder="drop"  # Supprimons toute autre colonne non list√©e
    )
    return transformeur  # Retournons le transformeur

@st.cache_resource(show_spinner=True)  # M√©morisons la ressource entra√Æn√©e (mod√®le) entre interactions
def entrainer_modele(donnees_fr: pd.DataFrame) -> Bunch:
    """Entra√Ænons un mod√®le RandomForest dans un pipeline : pr√©traitement -> SMOTE -> RandomForest."""
    # S√©parons X et y
    X_entree, y_cible = separer_X_y(donnees_fr)  # Pr√©parons les entr√©es et la cible
    # Construisons le transformeur de colonnes
    transformeur = construire_transformeur(donnees_fr)  # Cr√©ons le transformeur colonnes
    # Instancions le classifieur RandomForest
    classifieur = RandomForestClassifier(  # D√©finissons le mod√®le final
        n_estimators=NB_ARBRES_RF,  # Fixons le nombre d‚Äôarbres
        random_state=SEED_ALEATOIRE,  # Assurons la reproductibilit√©
        n_jobs=-1,  # Utilisons tous les c≈ìurs disponibles
        class_weight=None  # La gestion du d√©s√©quilibre est confi√©e √† SMOTE, pas aux poids
    )
    # Construisons un pipeline imbalanced-learn avec SMOTE entre le pr√©traitement et le classifieur
    pipeline = ImbPipeline(  # Cha√Ænons les √©tapes dans l‚Äôordre logique
        steps=[
            ("pretraitement", transformeur),  # Appliquons le transformeur (scaler + one-hot)
            ("smote", SMOTE(random_state=SEED_ALEATOIRE)),  # √âquilibrons les classes dans l‚Äôespace transform√©
            ("modele", classifieur),  # Appliquons le classifieur RF sur les donn√©es √©quilibr√©es
        ]
    )
    # D√©coupons en apprentissage/test
    X_app, X_test, y_app, y_test = train_test_split(  # S√©parons apprentissage et test
        X_entree, y_cible, test_size=TAILLE_TEST, random_state=SEED_ALEATOIRE, stratify=y_cible  # Stratifier pour garder le ratio
    )
    # Entra√Ænons le pipeline
    pipeline.fit(X_app, y_app)  # Ajustons l‚Äôensemble des √©tapes sur les donn√©es d‚Äôapprentissage
    # Pr√©dictions de contr√¥le sur le test
    y_pred = pipeline.predict(X_test)  # Pr√©dictions classes
    y_proba = pipeline.predict_proba(X_test)[:, 1]  # Probabilit√©s classe positive
    # Calculons des m√©triques cl√©s
    exactitude = accuracy_score(y_test, y_pred)  # Calculons l‚Äôaccuracy globale
    matrice = confusion_matrix(y_test, y_pred)  # Construisons la matrice de confusion
    rapport = classification_report(y_test, y_pred, output_dict=True)  # G√©n√©rons un rapport d√©taill√© (dict)
    # Retournons toutes les infos utiles dans un Bunch
    return Bunch(
        pipeline=pipeline,  # Renvoyons le pipeline complet pr√™t pour la pr√©diction
        X_test=X_test,  # Conserver X_test pour visualisations
        y_test=y_test,  # Conserver y_test pour m√©triques
        y_pred=y_pred,  # Conserver y_pred pour m√©triques
        y_proba=y_proba,  # Conserver y_proba pour courbes/threshold
        exactitude=exactitude,  # Score accuracy
        matrice=matrice,  # Matrice de confusion
        rapport=rapport  # Rapport d√©taill√© (precision/recall/f1)
    )

def dataframe_vers_csv_bytes(df: pd.DataFrame) -> bytes:
    """Convertissons un DataFrame en CSV (bytes) pour permettre le t√©l√©chargement sans √©crire sur disque."""
    # Cr√©ons un tampon m√©moire texte
    tampon = io.StringIO()  # Ouvrons un buffer en m√©moire
    # √âcrivons le DataFrame en CSV dans le tampon
    df.to_csv(tampon, index=False)  # Exportons sans l‚Äôindex
    # Convertissons en bytes
    return tampon.getvalue().encode("utf-8")  # Retournons les octets encod√©s en UTF-8

def dictionnaire_variables(donnees_fr: pd.DataFrame) -> pd.DataFrame:
    """Construisons un mini dictionnaire de donn√©es (nom, type, % manquants, exemples)."""
    # Pr√©parons une liste pour collecter les m√©ta-informations
    lignes = []  # Initialisons un conteneur vide
    # Parcourons chaque colonne pour en extraire les infos utiles
    for nom_colonne in donnees_fr.columns:  # It√©rons sur les colonnes
        type_col = str(donnees_fr[nom_colonne].dtype)  # R√©cup√©rons le type pandas de la colonne
        manquants = int(donnees_fr[nom_colonne].isna().sum())  # Comptons le nombre de valeurs manquantes
        pct_manq = round(100 * manquants / len(donnees_fr), 2)  # Calculons le pourcentage de manquants
        exemple = donnees_fr[nom_colonne].dropna().unique()[:3]  # Prenons quelques exemples de valeurs
        lignes.append({  # Ajoutons une ligne d'information
            "variable": nom_colonne,
            "type": type_col,
            "valeurs_exemple": list(exemple),
            "manquants": manquants,
            "%_manquants": pct_manq
        })
    # Convertissons la liste en DataFrame structur√©
    return pd.DataFrame(lignes)  # Retournons la table du dictionnaire

# -----------------------------
# 6) Chargement des donn√©es brutes, renommage et pr√©paration
# -----------------------------
donnees_brutes = charger_donnees()  # Chargeons le fichier CSV pour obtenir le dataset d‚Äôorigine
donnees_fr = renommer_colonnes_en_francais(donnees_brutes)  # Renommons les colonnes en fran√ßais pour l‚ÄôEDA
modele_infos = None  # Initialisons un conteneur pour accueillir le mod√®le entra√Æn√© (rempli dans l‚Äôonglet Mod√©lisation)

# -----------------------------
# 7) Barre d‚Äôent√™te (titre + rappel)
# -----------------------------
st.title("üí≥ Inclusion financi√®re ‚Äì Pr√©diction d'ouverture de compte bancaire")  # Affichons un titre clair
st.caption("Exploration, pr√©traitement, mod√©lisation et pr√©diction ‚Äì dataset d‚Äôinclusion financi√®re.")  # Ajoutons un sous-titre

# -----------------------------
# 8) Organisation en onglets (pages logiques)
# -----------------------------
onglets = st.tabs([  # Cr√©ons des onglets pour structurer l‚Äôapplication
    "üè† Accueil",            # Onglet 0 : Accueil
    "üîç Exploration",        # Onglet 1 : Exploration des donn√©es
    "üßπ Pr√©traitement",      # Onglet 2 : Pr√©traitement (manquants, doublons, √©quilibrage)
    "ü§ñ Mod√©lisation",       # Onglet 3 : Entra√Ænement et √©valuation du mod√®le
    "üéØ Pr√©diction",         # Onglet 4 : Interface de pr√©diction
    "üìë Profiling",          # Onglet 5 : Rapport ydata-profiling (HTML)
    "‚¨áÔ∏è T√©l√©chargements",    # Onglet 6 : Export des artefacts
    "‚ÑπÔ∏è √Ä propos"            # Onglet 7 : Contexte et objectifs
])

# -----------------------------
# 9) Onglet : Accueil
# -----------------------------
with onglets[0]:  # Entrons dans l‚Äôonglet Accueil
    st.subheader("Bienvenue üëã")  # Affichons un sous-titre convivial
    # Pr√©sentons le projet en quelques points cl√©s
    st.markdown(  # R√©digeons une description du projet pour situer l‚Äôutilisateur
        """
        **Objet du projet :** analyser et pr√©dire la probabilit√© qu‚Äôun individu poss√®de un compte bancaire,
        afin d‚Äô√©clairer des actions favorisant l‚Äôinclusion financi√®re.

        **Ce que vous pouvez faire ici :**
        - Explorer le jeu de donn√©es (profils, distributions, corr√©lations)
        - Visualiser le pr√©traitement (manquants, doublons, valeurs atypiques)
        - Entra√Æner un mod√®le *Random Forest* (avec SMOTE pour traiter le d√©s√©quilibre)
        - Tester des pr√©dictions sur des profils personnalis√©s
        - Consulter et t√©l√©charger le rapport de *profiling* et les artefacts (mod√®le, donn√©es pr√©par√©es)
        """
    )
    # Affichons quelques KPI rapides
    col_a, col_b, col_c, col_d = st.columns(4)  # Cr√©ons une grille de 4 colonnes pour les indicateurs
    with col_a:  # Dans la 1√®re colonne
        st.metric("Observations", value=f"{len(donnees_fr):,}".replace(",", " "))  # Affichons le nombre d‚Äôobservations
    with col_b:  # Dans la 2√®me colonne
        nb_vars = len(donnees_fr.columns)  # Comptons le nombre de variables
        st.metric("Variables", value=nb_vars)  # Affichons le nombre de colonnes
    with col_c:  # Dans la 3√®me colonne
        part_yes = (donnees_fr["compte_bancaire"].eq("Yes").mean() * 100) if not donnees_fr.empty else 0  # Calculons le % Yes
        st.metric("% Comptes (Yes)", value=f"{part_yes:.1f}%")  # Affichons le pourcentage de comptes
    with col_d:  # Dans la 4√®me colonne
        st.metric("Pays distincts", value=donnees_fr["pays"].nunique() if not donnees_fr.empty else 0)  # Affichons le nb de pays

# -----------------------------
# 10) Onglet : Exploration
# -----------------------------
with onglets[1]:  # Entrons dans l‚Äôonglet Exploration
    st.subheader("Aper√ßu des donn√©es")  # Affichons un sous-titre
    # Montrons les 10 premi√®res lignes pour un aper√ßu rapide
    st.dataframe(donnees_fr.head(10), use_container_width=True)  # Pr√©sentons un √©chantillon des donn√©es
    # Ajoutons des stats descriptives num√©riques
    st.subheader("Statistiques descriptives (num√©riques)")  # Indiquons la section de stats
    st.dataframe(donnees_fr.describe(include=[np.number]), use_container_width=True)  # R√©sumons les colonnes num√©riques
    # Ajoutons une table sur les manquants
    st.subheader("Valeurs manquantes")  # Indiquons la section sur les valeurs manquantes
    tableau_manquants = pd.DataFrame({  # Construisons un tableau synth√©tique des manquants
        "variable": donnees_fr.columns,
        "nb_manquants": donnees_fr.isna().sum().values,
        "%_manquants": (100 * donnees_fr.isna().sum().values / len(donnees_fr)).round(2)
    })  # Fermons la construction du DataFrame
    st.dataframe(tableau_manquants, use_container_width=True)  # Affichons la table des manquants
    # Visualisation : distribution √¢ge par pays (boxplot)
    st.subheader("Distribution de l‚Äô√¢ge par pays")  # Annon√ßons la visualisation
    if not donnees_fr.empty:  # V√©rifions que des donn√©es existent
        fig_age = px.box(donnees_fr, x="pays", y="age_repondant", points="outliers", title="√Çge par pays")  # Cr√©ons un boxplot
        st.plotly_chart(fig_age, use_container_width=True)  # Affichons le graphique
    # Dictionnaire de donn√©es synth√©tique
    st.subheader("Dictionnaire de donn√©es (vue rapide)")  # Indiquons la section
    st.dataframe(dictionnaire_variables(donnees_fr), use_container_width=True)  # Affichons le dictionnaire rapide

# -----------------------------
# 11) Onglet : Pr√©traitement
# -----------------------------
with onglets[2]:  # Entrons dans l‚Äôonglet Pr√©traitement
    st.subheader("Contr√¥les de qualit√©")  # Affichons un sous-titre
    # Comptage de doublons
    nb_doublons = int(donnees_fr.duplicated().sum())  # Comptons les doublons ligne √† ligne
    st.write(f"**Doublons d√©tect√©s :** {nb_doublons}")  # Affichons le nombre de doublons
    # Affichons les colonnes num√©riques pour une d√©tection visuelle d‚Äôoutliers
    st.subheader("Valeurs atypiques ‚Äì aper√ßu (bo√Ætes √† moustaches)")  # Indiquons la section outliers
    colonnes_num = donnees_fr.select_dtypes(include=[np.number]).columns.tolist()  # R√©cup√©rons les colonnes num√©riques
    for nom_col in colonnes_num:  # Parcourons chaque colonne num√©rique
        fig_box = go.Figure()  # Initialisons une figure Plotly
        fig_box.add_trace(go.Box(y=donnees_fr[nom_col], name=nom_col))  # Ajoutons une bo√Æte √† moustaches
        fig_box.update_layout(title=f"Bo√Æte √† moustaches ‚Äì {nom_col}")  # Donnons un titre lisible
        st.plotly_chart(fig_box, use_container_width=True)  # Affichons le graphique

# -----------------------------
# 12) Onglet : Mod√©lisation
# -----------------------------
with onglets[3]:  # Entrons dans l‚Äôonglet Mod√©lisation
    st.subheader("Entra√Ænement du mod√®le")  # Affichons un sous-titre
    # Bouton d‚Äôentra√Ænement pour d√©clencher le calcul et stocker le r√©sultat en cache ressource
    if st.button("üîÅ Entra√Æner / R√©entra√Æner le mod√®le"):  # Cr√©ons un bouton d‚Äôaction
        modele_infos = entrainer_modele(donnees_fr)  # Entra√Ænons et r√©cup√©rons les objets utiles
        st.success(f"Mod√®le entra√Æn√©. Exactitude (accuracy) : {modele_infos.exactitude:.3f}")  # Affichons l‚Äôaccuracy
    # Si un mod√®le est d√©j√† en cache (apr√®s clic), affichons ses m√©triques
    if "modele_infos" not in st.session_state:  # V√©rifions si le mod√®le n‚Äôest pas encore stock√© en session
        st.session_state["modele_infos"] = None  # Initialisons la cl√© de session
    if modele_infos is not None:  # Si un mod√®le vient d‚Äô√™tre entra√Æn√©
        st.session_state["modele_infos"] = modele_infos  # Conservons-le dans la session
    if st.session_state["modele_infos"] is not None:  # Si un mod√®le est dispo dans la session
        infos = st.session_state["modele_infos"]  # R√©cup√©rons les infos depuis la session
        # Affichons la matrice de confusion
        st.subheader("Matrice de confusion (jeu de test)")  # Annon√ßons la section
        matrice = infos.matrice  # R√©cup√©rons la matrice calcul√©e
        fig_cf = go.Figure(data=go.Heatmap(  # Construisons une heatmap pour la matrice
            z=matrice,  # Utilisons la matrice comme intensit√©
            x=["Pr√©dit: Non", "Pr√©dit: Oui"],  # L√©gendes colonnes
            y=["R√©el: Non", "R√©el: Oui"],  # L√©gendes lignes
            text=matrice,  # Affichons les valeurs
            texttemplate="%{text}",  # Formatons les cellules en texte brut
            colorscale="Blues"  # Choisissons une palette lisible
        ))  # Fermons la figure
        fig_cf.update_layout(title="Matrice de confusion")  # Ajoutons un titre
        st.plotly_chart(fig_cf, use_container_width=True)  # Affichons la figure
        # Affichons un r√©sum√© de classification (pr√©cision/rappel/F1)
        st.subheader("Rapport de classification")  # Annon√ßons la section
        rapport_df = pd.DataFrame(infos.rapport).transpose()  # Convertissons le rapport en DataFrame lisible
        st.dataframe(rapport_df, use_container_width=True)  # Affichons le rapport

# -----------------------------
# 13) Onglet : Pr√©diction
# -----------------------------
with onglets[4]:  # Entrons dans l‚Äôonglet Pr√©diction
    st.subheader("Pr√©dire l‚Äôouverture d‚Äôun compte bancaire")  # Affichons un sous-titre
    # R√©cup√©rons un mod√®le depuis la session si disponible
    infos = st.session_state.get("modele_infos", None)  # Lisons le mod√®le en session
    if infos is None:  # Si le mod√®le n‚Äôexiste pas encore
        st.info("Entra√Ænez d‚Äôabord le mod√®le dans l‚Äôonglet **Mod√©lisation**.")  # Guidons l‚Äôutilisateur
    else:  # Si le mod√®le est disponible
        # Construisons un formulaire utilisateur
        with st.form("formulaire_prediction"):  # Cr√©ons un formulaire pour regrouper les champs
            col_g, col_d = st.columns(2)  # Cr√©ons deux colonnes pour une saisie lisible
            with col_g:  # Colonne gauche : attributs d√©mographiques
                pays = st.selectbox("Pays", sorted(donnees_fr["pays"].dropna().unique()))  # Proposons les pays disponibles
                age = st.slider("√Çge du r√©pondant", min_value=15, max_value=100, value=30, step=1)  # Saisie de l‚Äô√¢ge
                genre = st.selectbox("Genre", sorted(donnees_fr["genre_repondant"].dropna().unique()))  # Saisie du genre
                statut = st.selectbox("Statut matrimonial", sorted(donnees_fr["statut_matrimonial"].dropna().unique()))  # Statut
            with col_d:  # Colonne droite : autres attributs
                local = st.selectbox("Type de localisation", sorted(donnees_fr["type_localisation"].dropna().unique()))  # Rural/Urban
                tel = st.selectbox("Acc√®s au t√©l√©phone", sorted(donnees_fr["acces_telephone"].dropna().unique()))  # Yes/No
                taille = st.slider("Taille du m√©nage", min_value=1, max_value=25, value=4, step=1)  # Taille du m√©nage
                etude = st.selectbox("Niveau d‚Äô√©ducation", sorted(donnees_fr["niveau_education"].dropna().unique()))  # Education
                emploi = st.selectbox("Type d‚Äôemploi", sorted(donnees_fr["type_emploi"].dropna().unique()))  # Job type
                relation = st.selectbox("Relation avec le chef de m√©nage", sorted(donnees_fr["relation_chef_menage"].dropna().unique()))  # Relation
                annee = st.selectbox("Ann√©e d‚Äôenqu√™te", sorted(donnees_fr["annee"].dropna().unique()))  # Ann√©e
            # Ajoutons un seuil de probabilit√© ajustable
            seuil = st.slider("Seuil de d√©cision (probabilit√© pour classer 'Oui')", 0.05, 0.95, 0.50, 0.01)  # Seuil
            # Bouton de soumission du formulaire
            soumis = st.form_submit_button("Lancer la pr√©diction")  # Cr√©ons le bouton de validation
        # Si l‚Äôutilisateur a soumis le formulaire
        if soumis:  # D√©tectons l‚Äô√©v√©nement de soumission
            # Construisons un DataFrame √† une ligne avec les m√™mes noms de colonnes (fran√ßais) que X_entree
            entree_utilisateur = pd.DataFrame([{  # Cr√©ons un DataFrame ligne unique
                "pays": pays,
                "annee": annee,
                "type_localisation": local,
                "acces_telephone": tel,
                "taille_menage": taille,
                "age_repondant": age,
                "genre_repondant": genre,
                "relation_chef_menage": relation,
                "statut_matrimonial": statut,
                "niveau_education": etude,
                "type_emploi": emploi
            }])  # Fermons la construction de la ligne
            # Alignons les colonnes de l‚Äôentr√©e utilisateur avec celles apprises par le pipeline (via le fit transform)
            # NB : Le ColumnTransformer g√®re tout via handle_unknown="ignore" (OneHotEncoder), donc pas besoin de mappage manuel.
            proba = infos.pipeline.predict_proba(entree_utilisateur)[:, 1][0]  # Pr√©diction de probabilit√© classe positive
            # Appliquons le seuil pour d√©terminer la classe pr√©dite
            classe = int(proba >= seuil)  # Classe 1 si probabilit√© >= seuil, sinon 0
            # Rendu des r√©sultats sous forme de colonnes
            c1, c2 = st.columns(2)  # Cr√©ons deux colonnes pour afficher r√©sultat + d√©cision
            with c1:  # Colonne de gauche
                st.success(f"Probabilit√© d'avoir un compte : **{proba:.2%}**")  # Affichons la probabilit√© format√©e
            with c2:  # Colonne de droite
                libelle = "Compte probable (Oui)" if classe == 1 else "Compte peu probable (Non)"  # Formulons le libell√©
                st.info(f"D√©cision (seuil {seuil:.0%}) : **{libelle}**")  # Affichons la d√©cision finale

# -----------------------------
# 14) Onglet : Profiling (rapport HTML)
# -----------------------------
with onglets[5]:  # Entrons dans l‚Äôonglet Profiling
    st.subheader("Rapport de profiling (ydata-profiling)")  # Affichons un sous-titre
    # V√©rifions l‚Äôexistence du fichier HTML
    if not os.path.exists(CHEMIN_PROFILING_HTML):  # Si le fichier n‚Äôexiste pas
        st.warning("Aucun rapport 'output.html' trouv√©. G√©n√©rez-le et placez-le √† la racine.")  # Avertissons l‚Äôutilisateur
    else:  # Si le fichier existe
        with open(CHEMIN_PROFILING_HTML, "r", encoding="utf-8") as f:  # Ouvrons le fichier HTML
            contenu_html = f.read()  # Lisons tout le contenu HTML
        composants.html(contenu_html, height=800, scrolling=True)  # Int√©grons le HTML dans l‚Äôapp avec d√©filement

# -----------------------------
# 15) Onglet : T√©l√©chargements
# -----------------------------
with onglets[6]:  # Entrons dans l‚Äôonglet T√©l√©chargements
    st.subheader("Export des artefacts")  # Affichons un sous-titre
    # Proposition de t√©l√©chargement des donn√©es renomm√©es
    st.write("T√©l√©chargez les **donn√©es renomm√©es (fran√ßais)** pour vos usages (EDA/archivage) :")  # Ajoutons une explication
    st.download_button(  # Cr√©ons un bouton de t√©l√©chargement
        label="‚¨áÔ∏è T√©l√©charger le CSV (colonnes en fran√ßais)",  # Intitul√© du bouton
        data=dataframe_vers_csv_bytes(donnees_fr),  # Donnons les octets du CSV
        file_name="donnees_inclusion_fr.csv",  # Nom du fichier de sortie
        mime="text/csv"  # Type MIME CSV
    )
    # Proposition de t√©l√©chargement du mod√®le (si entra√Æn√©)
    infos = st.session_state.get("modele_infos", None)  # R√©cup√©rons le mod√®le depuis la session
    if infos is not None:  # Si un mod√®le est dispo
        tampon_binaire = io.BytesIO()  # Ouvrons un tampon binaire en m√©moire
        pickle.dump(infos.pipeline, tampon_binaire)  # S√©rialisons le pipeline dans le tampon
        st.download_button(  # Cr√©ons un bouton de t√©l√©chargement
            label="‚¨áÔ∏è T√©l√©charger le mod√®le (pickle)",  # Intitul√© clair
            data=tampon_binaire.getvalue(),  # R√©cup√©rons les octets du tampon
            file_name="modele_inclusion.pkl",  # Nom du mod√®le √† t√©l√©charger
            mime="application/octet-stream"  # Type g√©n√©rique binaire
        )
    else:  # Si aucun mod√®le n‚Äôest disponible
        st.info("Aucun mod√®le √† t√©l√©charger pour l‚Äôinstant (entra√Ænez-le d'abord).")  # Guidons l‚Äôutilisateur

# -----------------------------
# 16) Onglet : √Ä propos
# -----------------------------
with onglets[7]:  # Entrons dans l‚Äôonglet √Ä propos
    st.subheader("Contexte du projet")  # Affichons un sous-titre
    # R√©sumons les r√©ponses attendues (de quoi traite, probl√®me, objectif)
    st.markdown(  # Affichons un r√©sum√© structur√©
        """
        **De quoi s‚Äôagit-il ?**  
        Projet d‚Äôinclusion financi√®re visant √† comprendre et **pr√©dire** l‚Äôouverture d‚Äôun compte bancaire.

        **Probl√®me √† r√©soudre :**  
        Faible taux de bancarisation et difficult√© √† **identifier les profils** susceptibles d‚Äôouvrir un compte.

        **Objectifs :**  
        - Explorer les facteurs socio-d√©mographiques impactant la possession d‚Äôun compte  
        - Construire un **mod√®le pr√©dictif** fiable (RandomForest + SMOTE)  
        - Fournir une **interface** de pr√©diction et d‚Äôanalyse d√©cisionnelle
        """
    )
    # Cr√©dit et versions
    st.caption("App Streamlit ‚Äì variables Python en fran√ßais, commentaires d√©taill√©s, profilage int√©gr√©.")
